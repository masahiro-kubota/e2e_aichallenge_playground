# E2E Planner 実装方針ガイドライン

本ドキュメントは、E2E Planner の開発におけるシナリオ定義、データ収集、学習、評価、および実験管理に関する長期的な実装方針をまとめたものです。

---

## 1. 全体アーキテクチャとツール構成

| 工程 | 役割 | 主要ツール | 備考 |
| :--- | :--- | :--- | :--- |
| **① 実験設計** | シナリオ・条件定義 | **Hydra** | YAML階層管理と実行時override |
| **② データ収集** | 並列シミュレーション | **Ray**, **tqdm** | 決定論的なセンサ生成を最優先 |
| **③ 前処理** | 特徴量化・正規化 | **NumPy**, **PyTorch** | 時系列固定長化と正規化パラメータ保存 |
| **④ 学習** | モデル最適化 | **PyTorch**, **Ray**, **Optuna** | 学習ログは **WandB** に集約 |
| **⑤ 評価** | 閉ループシミュレーション | **Ray**, **Plotly**, **Foxglove** | 総合評価結果は **MLflow** に集約 |
| **⑥ ワークフロー** | 依存関係管理 | **Make** / **doit** / **invoke** | `dvc.yaml` は不使用（軽量管理） |
| **⑦ 管理** | 結果・成果物管理 | **MLflow**, **DVC** | DVCバックエンドとして **MinIO** を使用 |

---

## 2. 工程別詳細方針

### ① シナリオ定義・実験設計
- **実験条件定義**: `Hydra` を使用。マップ、交通流、天候、センサ構成、seed等をYAML階層で管理し、実行時に柔軟にoverride可能にする。
- **シナリオ仕様**: 既存の `JSON` または `YAML` を使用。独自のDSLは構築しない。
- **実験ID生成**: 設定ファイルをハッシュ化してIDを生成。再実行やキャッシュ判定のキーとして利用する。

### ② データ収集（シミュレーション）
- **シミュレータ実行**: `Ray` による並列実行（1条件 × Nロールアウト）。
- **センサ生成**: LiDAR / Camera / State 等。決定論的（Determinism）な生成を最優先する。
- **データ保存**: `trajectory` / `obs` / `action` を保存。
  - **重要**: **HDF5は使用しない**。エピソード単位のファイル（NumPy `.npy`/`.npz` や `MCAP` 等）で保存する。
- **進捗管理**: `tqdm` を使用。Rayと併用して並列実行中の進捗を可視化。

### ③ 前処理・特徴量化
- **正規化**: 座標系や速度スケールを `NumPy` で処理。正規化に使用した統計パラメータも保存対象とする。
- **時系列整形**: `PyTorch Dataset` で固定長化、パディング、マスク処理を行う。
- **キャッシュ**: 中間生成物は `DVC` で管理し、再計算を回避。

### ④ 学習（E2E Planner）
- **モデル定義**: `PyTorch` (Diffusion / Transformer / CNN等)。
- **学習実行**: `Ray` を使用し、Multi-GPU拡張を視野に入れる。
- **ハイパラ探索**: `Optuna` + `Ray` で分散HPOを実施。
- **ログ管理**: **学習指標（Loss, Grad, LR等）の管理はすべて WandB に統一する。**

### ⑤ 評価（Closed-loop Simulation）
- **評価実行**: `Ray` を使用し、Policy-in-the-loop で再シミュレーションを行う。学習環境とは完全に分離する。
- **指標計算**: 衝突率、Jerk、Goal達成率等を `NumPy` / `pandas` で算出。
- **可視化**: `Plotly` で軌跡や分布をHTML化。挙動の詳細確認には `Foxglove` を使用して「なぜ失敗したか」を即理解できるようにする。
- **結果保存**: **総合評価の指標、シナリオ別集計、HTMLレポートは MLflow に保存する。**

### ⑥ ワークフロー制御
- **依存関係管理**: `collect` → `train` → `eval` のパイプラインを `Make`, `doit`, または `invoke` で制御。
- **定期実行**: 必要に応じて `Airflow` 等での Nightly Eval を実施。

---

## 3. データ・実験管理の境界ルール

### ルールA：DVC は「重い実体」を固定する
- **バックエンド**: **MinIO** を使用する。
- **管理対象**:
  - 収集データ（エピソード単位のファイル群）
  - 前処理済みデータ
  - 学習済みモデル（Checkpoint, ONNX, TorchScript）
  - 正規化統計量（Normalizer parameters）
  - 全工程で不変な固定ベンチマークセット
- **目的**: `git checkout` + `dvc pull` で過去の特定の実行環境（入力と成果物）を完全に復元可能にすること。

### ルールB：WandB は「プロセスの詳細」を記録する
- **管理対象**: 学習中の逐次ログ（Stepごとの Loss, Gradient, Learning Rate 等）、モデルの重みのヒストグラム。
- **目的**: 研究開発における学習の推移やモデル間の詳細比較。

### ルールC：MLflow は「ランの記録と評価結果」を残す
- **管理対象**:
  - 総合評価指標（Collision rate, Success rate, Jerk sum 等）
  - シナリオ別の集計データ（CSV / Parquet）
  - 可視化レポート（Plotly HTML, 失敗ケースのサマリ）
  - 実験メタ情報
- **目的**: 「どのモデルがどのデータを用いてどのような結果を出したか」という最終的なエビデンスを管理し、意思決定の拠点とする。

### ルールD：MLflow Run への参照記録（必須運用）
MLflow の各 Run には、再現性を確保するために以下のタグ/属性を必ず付与する：
- `git_commit`: 実行時のコード版。
- `dvc_data_path`: 入力データのDVCパス（例: `data/processed/v1`）。
- `dvc_model_path`: 評価に使用したモデルのDVCパス。
- `benchmark_id`: 評価に使用したシナリオセットの識別子。
- `hydra_resolved_config`: 解決済みの設定ファイル（Artifactとして保存）。

---

## 4. 運用上の基本方針
- **ディレクトリ構成の維持**: `experiment/conf` (Hydra), `scripts/` (主要工程), `data/` (DVC管理対象) の構造を保つ。
- **Determinism**: シミュレーションとデータ生成において、seedによる再現性を最優先する。
- **パイプライン管理**: `dvc.yaml` によるパイプライン定義は行わず、タスクランナー（Make等）でコードベースの制御を行う。
