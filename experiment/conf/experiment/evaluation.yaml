# @package _global_
# Evaluation Configuration

defaults:
  - base
  - _self_

agent: tiny_lidar

experiment:
  name: "evaluation"
  type: "evaluation"
  description: "Closed-loop evaluation of trained model"

system:
  nodes:
    # Base nodes from base.yaml
    - name: "Simulator"
      type: "KinematicSimulator"
      rate_hz: ${execution.clock_rate_hz}
      params:
        map_path: ${env.map_path}
        vehicle_params: ${vehicle}
        initial_state: ${env.initial_state}
        obstacles: ${env.obstacles}
    - name: "Sensor"
      type: "ideal_sensor.sensor_node.IdealSensorNode"
      rate_hz: 50.0
      params: {}
    - name: "Logger"
      type: "LoggerNode"
      rate_hz: ${execution.clock_rate_hz}
      params:
        output_mcap_path: ${postprocess.mcap.output_dir}/simulation.mcap
        map_path: ${env.map_path}
        track_path: ${env.track_path}
        vehicle_params: ${vehicle}
    # Add Supervisor node for evaluation
    - name: "Supervisor"
      type: "SupervisorNode"
      rate_hz: 10.0
      params:
        goal:
          enabled: true
          x: ${env.goal_position.x}
          y: ${env.goal_position.y}
          radius: ${env.goal_tolerance}
          min_elapsed_time: 20.0
        collision:
          enabled: true
        off_track:
          enabled: true

# Enable dashboard for evaluation
postprocess:
  dashboard:
    enabled: true
  inputs:
    - ${postprocess.mcap.output_dir}/simulation.mcap
